[
	{
		"reproduceVersion": "0.0.0-local",
		"timestamp": "2026-01-01T04:57:49.805Z",
		"os": "linux",
		"arch": "x64",
		"strategy": "npm:6.4.1",
		"reproduced": false,
		"attested": false,
		"package": {
			"spec": "adm-zip@0.4.13",
			"name": "adm-zip",
			"version": "0.4.13",
			"location": "https://registry.npmjs.org/adm-zip/-/adm-zip-0.4.13.tgz",
			"integrity": "sha512-fERNJX8sOXfel6qCBCMPvZLzENBEhZTzKqg6vrOW5pvoEaQuJhRU4ndTAh6lHOxn1I6jnz2NHra56ZODM751uw==",
			"publishedAt": "2018-11-13T07:10:21.743Z",
			"publishedWith": {
				"node": "11.1.0",
				"npm": "6.4.1"
			}
		},
		"source": {
			"integrity": "sha512-WLSMCecZ2BkuTjI4LQc2imosa0VBzQC8dBGInV33yRO+DhPaIsMh10wFsLww6Rje0vAGxLvRV+3UUgcmd7p0hw==",
			"location": "git+https://github.com/cthackers/adm-zip.git",
			"spec": "github:cthackers/adm-zip#e3fbb92496b0571ce4fd1376dab7ffe3dfa09c20"
		},
		"comparisonHash": "8a2a8dcbb729bf3ee9216e490c955701f0ddebe1",
		"diff": {
			"files": {
				"MIT-LICENSE.txt": {
					"match": false,
					"packageHash": "7ef51ca96ae084da522db7542252e5542876e845d6551eb199f361b91035048c",
					"size": 1147,
					"status": "missing-in-source"
				},
				"README.md": {
					"diff": "--- published/README.md\n+++ rebuilt/README.md\n@@ -1,65 +1,87 @@\n-# ADM-ZIP for NodeJS with added support for electron original-fs\r\n-\r\n-ADM-ZIP is a pure JavaScript implementation for zip data compression for [NodeJS](http://nodejs.org/). \r\n-\r\n-# Installation\r\n-\r\n-With [npm](http://npmjs.org) do:\r\n-\r\n-    $ npm install adm-zip\r\n-\t\r\n-## What is it good for?\r\n-The library allows you to:\r\n-\r\n-* decompress zip files directly to disk or in memory buffers\r\n-* compress files and store them to disk in .zip format or in compressed buffers\r\n-* update content of/add new/delete files from an existing .zip\r\n-\r\n-# Dependencies\r\n-There are no other nodeJS libraries that ADM-ZIP is dependent of\r\n-\r\n-# Examples\r\n-\r\n-## Basic usage\r\n-```javascript\r\n-\r\n-\tvar AdmZip = require('adm-zip');\r\n-\r\n-\t// reading archives\r\n-\tvar zip = new AdmZip(\"./my_file.zip\");\r\n-\tvar zipEntries = zip.getEntries(); // an array of ZipEntry records\r\n-\r\n-\tzipEntries.forEach(function(zipEntry) {\r\n-\t    console.log(zipEntry.toString()); // outputs zip entries information\r\n-\t\tif (zipEntry.entryName == \"my_file.txt\") {\r\n-\t\t     console.log(zipEntry.getData().toString('utf8')); \r\n-\t\t}\r\n-\t});\r\n-\t// outputs the content of some_folder/my_file.txt\r\n-\tconsole.log(zip.readAsText(\"some_folder/my_file.txt\")); \r\n-\t// extracts the specified file to the specified location\r\n-\tzip.extractEntryTo(/*entry name*/\"some_folder/my_file.txt\", /*target path*/\"/home/me/tempfolder\", /*maintainEntryPath*/false, /*overwrite*/true);\r\n-\t// extracts everything\r\n-\tzip.extractAllTo(/*target path*/\"/home/me/zipcontent/\", /*overwrite*/true);\r\n-\t\r\n-\t\r\n-\t// creating archives\r\n-\tvar zip = new AdmZip();\r\n-\t\r\n-\t// add file directly\r\n-\tvar content = \"inner content of the file\";\r\n-\tzip.addFile(\"test.txt\", Buffer.alloc(content.length, content), \"entry comment goes here\");\r\n-\t// add local file\r\n-\tzip.addLocalFile(\"/home/me/some_picture.png\");\r\n-\t// get everything as a buffer\r\n-\tvar willSendthis = zip.toBuffer();\r\n-\t// or write everything to disk\r\n-\tzip.writeZip(/*target file name*/\"/home/me/files.zip\");\r\n-\t\r\n-\t\r\n-\t// ... more examples in the wiki\r\n-```\r\n-\r\n-For more detailed information please check out the [wiki](https://github.com/cthackers/adm-zip/wiki).\r\n-\r\n-[![build status](https://secure.travis-ci.org/cthackers/adm-zip.png)](http://travis-ci.org/cthackers/adm-zip)\r\n+# ADM-ZIP for NodeJS\n+\n+ADM-ZIP is a pure JavaScript implementation for zip data compression for [NodeJS](https://nodejs.org/).\n+\n+<a href=\"https://github.com/cthackers/adm-zip/actions/workflows/ci.yml\">\n+  <img src=\"https://github.com/cthackers/adm-zip/actions/workflows/ci.yml/badge.svg\" alt=\"Build Status\">\n+</a>\n+\n+# Installation\n+\n+With [npm](https://www.npmjs.com/) do:\n+\n+    $ npm install adm-zip\n+\n+**Electron** file system support described below.\n+\n+## What is it good for?\n+\n+The library allows you to:\n+\n+-   decompress zip files directly to disk or in memory buffers\n+-   compress files and store them to disk in .zip format or in compressed buffers\n+-   update content of/add new/delete files from an existing .zip\n+\n+# Dependencies\n+\n+There are no other nodeJS libraries that ADM-ZIP is dependent of\n+\n+# Examples\n+\n+## Basic usage\n+\n",
					"match": false,
					"packageHash": "35a0d6b31505823875bc23807034b899061fdd1d76113a9f5174a4facda66c9b",
					"size": 2191,
					"sourceHash": "1aa164b27b6e129f9a3c061621031aefbabebf1c7cbacba47e03f91582fb15ea",
					"status": "content"
				},
				"adm-zip.js": {
					"diff": "--- published/adm-zip.js\n+++ rebuilt/adm-zip.js\n@@ -1,553 +1,949 @@\n-var Utils = require(\"./util\");\r\n-var fs = Utils.FileSystem.require(),\r\n-\tpth = require(\"path\");\r\n-\r\n-fs.existsSync = fs.existsSync || pth.existsSync;\r\n-\r\n-var ZipEntry = require(\"./zipEntry\"),\r\n-\tZipFile = require(\"./zipFile\");\r\n-\r\n-var isWin = /^win/.test(process.platform);\r\n-\r\n-\r\n-module.exports = function (/*String*/input) {\r\n-\tvar _zip = undefined,\r\n-\t\t_filename = \"\";\r\n-\r\n-\tif (input && typeof input === \"string\") { // load zip file\r\n-\t\tif (fs.existsSync(input)) {\r\n-\t\t\t_filename = input;\r\n-\t\t\t_zip = new ZipFile(input, Utils.Constants.FILE);\r\n-\t\t} else {\r\n-\t\t\tthrow Utils.Errors.INVALID_FILENAME;\r\n-\t\t}\r\n-\t} else if (input && Buffer.isBuffer(input)) { // load buffer\r\n-\t\t_zip = new ZipFile(input, Utils.Constants.BUFFER);\r\n-\t} else { // create new zip file\r\n-\t\t_zip = new ZipFile(null, Utils.Constants.NONE);\r\n-\t}\r\n-\r\n-\tfunction sanitize(prefix, name) {\r\n-\t\tprefix = pth.resolve(pth.normalize(prefix));\r\n-\t\tvar parts = name.split('/');\r\n-\t\tfor (var i = 0, l = parts.length; i < l; i++) {\r\n-\t\t\tvar path = pth.normalize(pth.join(prefix, parts.slice(i, l).join(pth.sep)));\r\n-\t\t\tif (path.indexOf(prefix) === 0) {\r\n-\t\t\t\treturn path;\r\n-\t\t\t}\r\n-\t\t}\r\n-\t\treturn pth.normalize(pth.join(prefix, pth.basename(name)));\r\n-\t}\r\n-\r\n-\tfunction getEntry(/*Object*/entry) {\r\n-\t\tif (entry && _zip) {\r\n-\t\t\tvar item;\r\n-\t\t\t// If entry was given as a file name\r\n-\t\t\tif (typeof entry === \"string\")\r\n-\t\t\t\titem = _zip.getEntry(entry);\r\n-\t\t\t// if entry was given as a ZipEntry object\r\n-\t\t\tif (typeof entry === \"object\" && typeof entry.entryName !== \"undefined\" && typeof entry.header !== \"undefined\")\r\n-\t\t\t\titem = _zip.getEntry(entry.entryName);\r\n-\r\n-\t\t\tif (item) {\r\n-\t\t\t\treturn item;\r\n-\t\t\t}\r\n-\t\t}\r\n-\t\treturn null;\r\n-\t}\r\n-\r\n-\treturn {\r\n-\t\t/**\r\n-\t\t * Extracts the given entry from the archive and returns the content as a Buffer object\r\n-\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n-\t\t *\r\n-\t\t * @return Buffer or Null in case of error\r\n-\t\t */\r\n-\t\treadFile: function (/*Object*/entry) {\r\n-\t\t\tvar item = getEntry(entry);\r\n-\t\t\treturn item && item.getData() || null;\r\n-\t\t},\r\n-\r\n-\t\t/**\r\n-\t\t * Asynchronous readFile\r\n-\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n-\t\t * @param callback\r\n-\t\t *\r\n-\t\t * @return Buffer or Null in case of error\r\n-\t\t */\r\n-\t\treadFileAsync: function (/*Object*/entry, /*Function*/callback) {\r\n-\t\t\tvar item = getEntry(entry);\r\n-\t\t\tif (item) {\r\n-\t\t\t\titem.getDataAsync(callback);\r\n-\t\t\t} else {\r\n-\t\t\t\tcallback(null, \"getEntry failed for:\" + entry)\r\n-\t\t\t}\r\n-\t\t},\r\n-\r\n-\t\t/**\r\n-\t\t * Extracts the given entry from the archive and returns the content as plain text in the given encoding\r\n-\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n-\t\t * @param encoding Optional. If no encoding is specified utf8 is used\r\n-\t\t *\r\n-\t\t * @return String\r\n-\t\t */\r\n-\t\treadAsText: function (/*Object*/entry, /*String - Optional*/encoding) {\r\n-\t\t\tvar item = getEntry(entry);\r\n-\t\t\tif (item) {\r\n-\t\t\t\tvar data = item.getData();\r\n",
					"match": false,
					"packageHash": "00857a227e59d12f4594f9baefe4e8be4ec194ecc07823bac994b4106c7d01d0",
					"size": 15515,
					"sourceHash": "dc6a2239b69829b7d20aeefc9f5540aa69564d0cac476e442afeb030ae64ca07",
					"status": "content"
				},
				"headers/entryHeader.js": {
					"diff": "--- published/headers/entryHeader.js\n+++ rebuilt/headers/entryHeader.js\n@@ -1,261 +1,377 @@\n-var Utils = require(\"../util\"),\r\n-    Constants = Utils.Constants;\r\n-\r\n-/* The central directory file header */\r\n-module.exports = function () {\r\n-    var _verMade = 0x0A,\r\n-        _version = 0x0A,\r\n-        _flags = 0,\r\n-        _method = 0,\r\n-        _time = 0,\r\n-        _crc = 0,\r\n-        _compressedSize = 0,\r\n-        _size = 0,\r\n-        _fnameLen = 0,\r\n-        _extraLen = 0,\r\n-\r\n-        _comLen = 0,\r\n-        _diskStart = 0,\r\n-        _inattr = 0,\r\n-        _attr = 0,\r\n-        _offset = 0;\r\n-\r\n-    var _dataHeader = {};\r\n-\r\n-    function setTime(val) {\r\n-        val = new Date(val);\r\n-        _time = (val.getFullYear() - 1980 & 0x7f) << 25  // b09-16 years from 1980\r\n-            | (val.getMonth() + 1) << 21                 // b05-08 month\r\n-            | val.getDate() << 16                        // b00-04 hour\r\n-\r\n-            // 2 bytes time\r\n-            | val.getHours() << 11    // b11-15 hour\r\n-            | val.getMinutes() << 5   // b05-10 minute\r\n-            | val.getSeconds() >> 1;  // b00-04 seconds divided by 2\r\n-    }\r\n-\r\n-    setTime(+new Date());\r\n-\r\n-    return {\r\n-        get made () { return _verMade; },\r\n-        set made (val) { _verMade = val; },\r\n-\r\n-        get version () { return _version; },\r\n-        set version (val) { _version = val },\r\n-\r\n-        get flags () { return _flags },\r\n-        set flags (val) { _flags = val; },\r\n-\r\n-        get method () { return _method; },\r\n-        set method (val) { _method = val; },\r\n-\r\n-        get time () { return new Date(\r\n-            ((_time >> 25) & 0x7f) + 1980,\r\n-            ((_time >> 21) & 0x0f) - 1,\r\n-            (_time >> 16) & 0x1f,\r\n-            (_time >> 11) & 0x1f,\r\n-            (_time >> 5) & 0x3f,\r\n-            (_time & 0x1f) << 1\r\n-        );\r\n-        },\r\n-        set time (val) {\r\n-            setTime(val);\r\n-        },\r\n-\r\n-        get crc () { return _crc; },\r\n-        set crc (val) { _crc = val; },\r\n-\r\n-        get compressedSize () { return _compressedSize; },\r\n-        set compressedSize (val) { _compressedSize = val; },\r\n-\r\n-        get size () { return _size; },\r\n-        set size (val) { _size = val; },\r\n-\r\n-        get fileNameLength () { return _fnameLen; },\r\n-        set fileNameLength (val) { _fnameLen = val; },\r\n-\r\n-        get extraLength () { return _extraLen },\r\n-        set extraLength (val) { _extraLen = val; },\r\n-\r\n-        get commentLength () { return _comLen },\r\n-        set commentLength (val) { _comLen = val },\r\n-\r\n-        get diskNumStart () { return _diskStart },\r\n-        set diskNumStart (val) { _diskStart = val },\r\n-\r\n-        get inAttr () { return _inattr },\r\n-        set inAttr (val) { _inattr = val },\r\n-\r\n-        get attr () { return _attr },\r\n-        set attr (val) { _attr = val },\r\n-\r\n-        get offset () { return _offset },\r\n-        set offset (val) { _offset = val },\r\n-\r\n-        get encripted () { return (_flags & 1) === 1 },\r\n-\r\n-        get entryHeaderSize () {\r\n",
					"match": false,
					"packageHash": "21bf1c9af56b60eb5f8b5865ccfa9e94e9eb9523848152d2f6e3c42a16d4c993",
					"size": 10464,
					"sourceHash": "51233162e8fb1affd4a4f45a196b5a50d38a78bd0979370f7fd2e81518c64376",
					"status": "content"
				},
				"headers/mainHeader.js": {
					"diff": "--- published/headers/mainHeader.js\n+++ rebuilt/headers/mainHeader.js\n@@ -1,80 +1,130 @@\n-var Utils = require(\"../util\"),\r\n-    Constants = Utils.Constants;\r\n-\r\n-/* The entries in the end of central directory */\r\n-module.exports = function () {\r\n-    var _volumeEntries = 0,\r\n-        _totalEntries = 0,\r\n-        _size = 0,\r\n-        _offset = 0,\r\n-        _commentLength = 0;\r\n-\r\n-    return {\r\n-        get diskEntries () { return _volumeEntries },\r\n-        set diskEntries (/*Number*/val) { _volumeEntries = _totalEntries = val; },\r\n-\r\n-        get totalEntries () { return _totalEntries },\r\n-        set totalEntries (/*Number*/val) { _totalEntries = _volumeEntries = val; },\r\n-\r\n-        get size () { return _size },\r\n-        set size (/*Number*/val) { _size = val; },\r\n-\r\n-        get offset () { return _offset },\r\n-        set offset (/*Number*/val) { _offset = val; },\r\n-\r\n-        get commentLength () { return _commentLength },\r\n-        set commentLength (/*Number*/val) { _commentLength = val; },\r\n-\r\n-        get mainHeaderSize () {\r\n-            return Constants.ENDHDR + _commentLength;\r\n-        },\r\n-\r\n-        loadFromBinary : function(/*Buffer*/data) {\r\n-            // data should be 22 bytes and start with \"PK 05 06\"\r\n-            if (data.length !== Constants.ENDHDR || data.readUInt32LE(0) !== Constants.ENDSIG)\r\n-                throw Utils.Errors.INVALID_END;\r\n-\r\n-            // number of entries on this volume\r\n-            _volumeEntries = data.readUInt16LE(Constants.ENDSUB);\r\n-            // total number of entries\r\n-            _totalEntries = data.readUInt16LE(Constants.ENDTOT);\r\n-            // central directory size in bytes\r\n-            _size = data.readUInt32LE(Constants.ENDSIZ);\r\n-            // offset of first CEN header\r\n-            _offset = data.readUInt32LE(Constants.ENDOFF);\r\n-            // zip file comment length\r\n-            _commentLength = data.readUInt16LE(Constants.ENDCOM);\r\n-        },\r\n-\r\n-        toBinary : function() {\r\n-           var b = Buffer.alloc(Constants.ENDHDR + _commentLength);\r\n-            // \"PK 05 06\" signature\r\n-            b.writeUInt32LE(Constants.ENDSIG, 0);\r\n-            b.writeUInt32LE(0, 4);\r\n-            // number of entries on this volume\r\n-            b.writeUInt16LE(_volumeEntries, Constants.ENDSUB);\r\n-            // total number of entries\r\n-            b.writeUInt16LE(_totalEntries, Constants.ENDTOT);\r\n-            // central directory size in bytes\r\n-            b.writeUInt32LE(_size, Constants.ENDSIZ);\r\n-            // offset of first CEN header\r\n-            b.writeUInt32LE(_offset, Constants.ENDOFF);\r\n-            // zip file comment length\r\n-            b.writeUInt16LE(_commentLength, Constants.ENDCOM);\r\n-            // fill comment memory with spaces so no garbage is left there\r\n-            b.fill(\" \", Constants.ENDHDR);\r\n-\r\n-            return b;\r\n-        },\r\n-\r\n-        toString : function() {\r\n-            return '{\\n' +\r\n-                '\\t\"diskEntries\" : ' + _volumeEntries + \",\\n\" +\r\n-                '\\t\"totalEntries\" : ' + _totalEntries + \",\\n\" +\r\n-                '\\t\"size\" : ' + _size + \" bytes,\\n\" +\r\n-                '\\t\"offset\" : 0x' + _offset.toString(16).toUpperCase() + \",\\n\" +\r\n-                '\\t\"commentLength\" : 0x' + _commentLength + \"\\n\" +\r\n-            '}';\r\n-        }\r\n-    }\r\n-};\n\\ No newline at end of file\n+var Utils = require(\"../util\"),\n+    Constants = Utils.Constants;\n+\n+/* The entries in the end of central directory */\n+module.exports = function () {\n+    var _volumeEntries = 0,\n+        _totalEntries = 0,\n+        _size = 0,\n+        _offset = 0,\n+        _commentLength = 0;\n+\n+    return {\n+        get diskEntries() {\n+            return _volumeEntries;\n+        },\n+        set diskEntries(/*Number*/ val) {\n",
					"match": false,
					"packageHash": "3a2682fd4628f2649ba43a93695c08b4867a8298b270eb37e18bba237d32c66d",
					"size": 3164,
					"sourceHash": "28dd1a0db451bc94d8f3234e57d8192ba17154118f841c398e0de35acea286ee",
					"status": "content"
				},
				"methods/deflater.js": {
					"diff": "--- published/methods/deflater.js\n+++ rebuilt/methods/deflater.js\n@@ -1,31 +1,33 @@\n-module.exports = function (/*Buffer*/inbuf) {\r\n-\r\n-  var zlib = require(\"zlib\");\r\n-  \r\n-  var opts = {chunkSize: (parseInt(inbuf.length / 1024) + 1) * 1024};\r\n-  \r\n-  return {\r\n-    deflate: function () {\r\n-      return zlib.deflateRawSync(inbuf, opts);\r\n-    },\r\n-\r\n-    deflateAsync: function (/*Function*/callback) {\r\n-      var tmp = zlib.createDeflateRaw(opts), parts = [], total = 0;\r\n-      tmp.on('data', function (data) {\r\n-        parts.push(data);\r\n-        total += data.length;\r\n-      });\r\n-      tmp.on('end', function () {\r\n-        var buf = Buffer.alloc(total), written = 0;\r\n-        buf.fill(0);\r\n-        for (var i = 0; i < parts.length; i++) {\r\n-          var part = parts[i];\r\n-          part.copy(buf, written);\r\n-          written += part.length;\r\n-        }\r\n-        callback && callback(buf);\r\n-      });\r\n-      tmp.end(inbuf);\r\n-    }\r\n-  }\r\n-};\r\n+module.exports = function (/*Buffer*/ inbuf) {\n+    var zlib = require(\"zlib\");\n+\n+    var opts = { chunkSize: (parseInt(inbuf.length / 1024) + 1) * 1024 };\n+\n+    return {\n+        deflate: function () {\n+            return zlib.deflateRawSync(inbuf, opts);\n+        },\n+\n+        deflateAsync: function (/*Function*/ callback) {\n+            var tmp = zlib.createDeflateRaw(opts),\n+                parts = [],\n+                total = 0;\n+            tmp.on(\"data\", function (data) {\n+                parts.push(data);\n+                total += data.length;\n+            });\n+            tmp.on(\"end\", function () {\n+                var buf = Buffer.alloc(total),\n+                    written = 0;\n+                buf.fill(0);\n+                for (var i = 0; i < parts.length; i++) {\n+                    var part = parts[i];\n+                    part.copy(buf, written);\n+                    written += part.length;\n+                }\n+                callback && callback(buf);\n+            });\n+            tmp.end(inbuf);\n+        }\n+    };\n+};\n",
					"match": false,
					"packageHash": "b8dde8a93d7e4419325b6eaf369703bf9ed9d2e87374fdc3dafe2551489629bb",
					"size": 848,
					"sourceHash": "6dc41b2460594cfa5136b797653c166b2f7403820a40f2fca17cca35a5de1b5f",
					"status": "content"
				},
				"methods/index.js": {
					"diff": "--- published/methods/index.js\n+++ rebuilt/methods/index.js\n@@ -1,2 +1,3 @@\n-exports.Deflater = require(\"./deflater\");\r\n-exports.Inflater = require(\"./inflater\");\n\\ No newline at end of file\n+exports.Deflater = require(\"./deflater\");\n+exports.Inflater = require(\"./inflater\");\n+exports.ZipCrypto = require(\"./zipcrypto\");\n",
					"match": false,
					"packageHash": "ba1d533124490473f4c772ee4d00c3557abdd0c2d6e681b69bcfe01ed772df9e",
					"size": 84,
					"sourceHash": "d67714f1a04be942f90be77069af3ff4214aa8ee84b26edeff3a87eb0d8e2dc0",
					"status": "content"
				},
				"methods/inflater.js": {
					"diff": "--- published/methods/inflater.js\n+++ rebuilt/methods/inflater.js\n@@ -1,29 +1,34 @@\n-module.exports = function (/*Buffer*/inbuf) {\r\n-\r\n-  var zlib = require(\"zlib\");\r\n-\r\n-  return {\r\n-    inflate: function () {\r\n-      return zlib.inflateRawSync(inbuf);\r\n-    },\r\n-\r\n-    inflateAsync: function (/*Function*/callback) {\r\n-      var tmp = zlib.createInflateRaw(), parts = [], total = 0;\r\n-      tmp.on('data', function (data) {\r\n-        parts.push(data);\r\n-        total += data.length;\r\n-      });\r\n-      tmp.on('end', function () {\r\n-        var buf = Buffer.alloc(total), written = 0;\r\n-        buf.fill(0);\r\n-        for (var i = 0; i < parts.length; i++) {\r\n-          var part = parts[i];\r\n-          part.copy(buf, written);\r\n-          written += part.length;\r\n-        }\r\n-        callback && callback(buf);\r\n-      });\r\n-      tmp.end(inbuf);\r\n-    }\r\n-  }\r\n-};\r\n+const version = +(process.versions ? process.versions.node : \"\").split(\".\")[0] || 0;\n+\n+module.exports = function (/*Buffer*/ inbuf, /*number*/ expectedLength) {\n+    var zlib = require(\"zlib\");\n+    const option = version >= 15 && expectedLength > 0 ? { maxOutputLength: expectedLength } : {};\n+\n+    return {\n+        inflate: function () {\n+            return zlib.inflateRawSync(inbuf, option);\n+        },\n+\n+        inflateAsync: function (/*Function*/ callback) {\n+            var tmp = zlib.createInflateRaw(option),\n+                parts = [],\n+                total = 0;\n+            tmp.on(\"data\", function (data) {\n+                parts.push(data);\n+                total += data.length;\n+            });\n+            tmp.on(\"end\", function () {\n+                var buf = Buffer.alloc(total),\n+                    written = 0;\n+                buf.fill(0);\n+                for (var i = 0; i < parts.length; i++) {\n+                    var part = parts[i];\n+                    part.copy(buf, written);\n+                    written += part.length;\n+                }\n+                callback && callback(buf);\n+            });\n+            tmp.end(inbuf);\n+        }\n+    };\n+};\n",
					"match": false,
					"packageHash": "e2c03c7cc16b72156063a324e87c91ac0cf6f7c58f6ce938536671d3ac1067ba",
					"size": 761,
					"sourceHash": "c5e4531a11385050d77a5069487b0be8e85c8e44fe6b214d68def321e74528ce",
					"status": "content"
				},
				"package.json": {
					"diff": "--- published/package.json\n+++ rebuilt/package.json\n@@ -1,43 +1,49 @@\n-{\r\n-  \"name\": \"adm-zip\",\r\n-  \"version\": \"0.4.13\",\r\n-  \"description\": \"Javascript implementation of zip for nodejs with support for electron original-fs. Allows user to create or extract zip files both in memory or to/from disk\",\r\n-  \"scripts\": {\r\n-    \"test\": \"mocha test/mocha.js\"\r\n-  },\r\n-  \"keywords\": [\r\n-    \"zip\",\r\n-    \"methods\",\r\n-    \"archive\",\r\n-    \"unzip\"\r\n-  ],\r\n-  \"homepage\": \"https://github.com/cthackers/adm-zip\",\r\n-  \"author\": \"Nasca Iacob <sy@another-d-mention.ro> (https://github.com/cthackers)\",\r\n-  \"bugs\": {\r\n-    \"email\": \"sy@another-d-mention.ro\",\r\n-    \"url\": \"https://github.com/cthackers/adm-zip/issues\"\r\n-  },\r\n-  \"license\": \"MIT\",\r\n-  \"files\": [\r\n-    \"adm-zip.js\",\r\n-    \"headers\",\r\n-    \"methods\",\r\n-    \"util\",\r\n-    \"zipEntry.js\",\r\n-    \"zipFile.js\",\r\n-    \"MIT-LICENSE.txt\"\r\n-  ],\r\n-  \"main\": \"adm-zip.js\",\r\n-  \"repository\": {\r\n-    \"type\": \"git\",\r\n-    \"url\": \"https://github.com/cthackers/adm-zip.git\"\r\n-  },\r\n-  \"engines\": {\r\n-    \"node\": \">=0.3.0\"\r\n-  },\r\n-  \"devDependencies\": {\r\n-    \"chai\": \"^4.1.2\",\r\n-    \"mocha\": \"^5.2.0\",\r\n-    \"rimraf\": \"^2.6.2\"\r\n-  }\r\n-}\r\n+{\n+  \"name\": \"adm-zip\",\n+  \"version\": \"0.5.16\",\n+  \"description\": \"Javascript implementation of zip for nodejs with support for electron original-fs. Allows user to create or extract zip files both in memory or to/from disk\",\n+  \"scripts\": {\n+    \"test\": \"mocha -R spec\",\n+    \"test:format\": \"npm run format:prettier:raw -- --check\",\n+    \"format\": \"npm run format:prettier\",\n+    \"format:prettier\": \"npm run format:prettier:raw -- --write\",\n+    \"format:prettier:raw\": \"prettier \\\"**/*.{js,yml,json}\\\"\"\n+  },\n+  \"keywords\": [\n+    \"zip\",\n+    \"methods\",\n+    \"archive\",\n+    \"unzip\"\n+  ],\n+  \"homepage\": \"https://github.com/cthackers/adm-zip\",\n+  \"author\": \"Nasca Iacob <sy@another-d-mention.ro> (https://github.com/cthackers)\",\n+  \"bugs\": {\n+    \"email\": \"sy@another-d-mention.ro\",\n+    \"url\": \"https://github.com/cthackers/adm-zip/issues\"\n+  },\n+  \"license\": \"MIT\",\n+  \"files\": [\n+    \"adm-zip.js\",\n+    \"headers\",\n+    \"methods\",\n+    \"util\",\n+    \"zipEntry.js\",\n+    \"zipFile.js\",\n+    \"LICENSE\"\n+  ],\n+  \"main\": \"adm-zip.js\",\n+  \"repository\": {\n+    \"type\": \"git\",\n+    \"url\": \"https://github.com/cthackers/adm-zip.git\"\n+  },\n+  \"engines\": {\n+    \"node\": \">=12.0\"\n+  },\n+  \"devDependencies\": {\n+    \"chai\": \"^4.3.4\",\n+    \"iconv-lite\": \"^0.6.3\",\n+    \"mocha\": \"^10.2.0\",\n+    \"prettier\": \"^3.3.2\",\n+    \"rimraf\": \"^3.0.2\"\n+  }\n+}\n",
					"match": false,
					"packageHash": "c59433d229e20331a1ac09ff1d919f9c4b26b5f5b1b68295ac1cb9e08ad9cea1",
					"size": 1062,
					"sourceHash": "2de3ef9fc3bad6955f503dc641da2db24626760ce1004fe6929cc5e64737ad35",
					"status": "content"
				},
				"util/constants.js": {
					"diff": "--- published/util/constants.js\n+++ rebuilt/util/constants.js\n@@ -1,115 +1,142 @@\n-module.exports = {\r\n-    /* The local file header */\r\n-    LOCHDR           : 30, // LOC header size\r\n-    LOCSIG           : 0x04034b50, // \"PK\\003\\004\"\r\n-    LOCVER           : 4,\t// version needed to extract\r\n-    LOCFLG           : 6, // general purpose bit flag\r\n-    LOCHOW           : 8, // compression method\r\n-    LOCTIM           : 10, // modification time (2 bytes time, 2 bytes date)\r\n-    LOCCRC           : 14, // uncompressed file crc-32 value\r\n-    LOCSIZ           : 18, // compressed size\r\n-    LOCLEN           : 22, // uncompressed size\r\n-    LOCNAM           : 26, // filename length\r\n-    LOCEXT           : 28, // extra field length\r\n-\r\n-    /* The Data descriptor */\r\n-    EXTSIG           : 0x08074b50, // \"PK\\007\\008\"\r\n-    EXTHDR           : 16, // EXT header size\r\n-    EXTCRC           : 4, // uncompressed file crc-32 value\r\n-    EXTSIZ           : 8, // compressed size\r\n-    EXTLEN           : 12, // uncompressed size\r\n-\r\n-    /* The central directory file header */\r\n-    CENHDR           : 46, // CEN header size\r\n-    CENSIG           : 0x02014b50, // \"PK\\001\\002\"\r\n-    CENVEM           : 4, // version made by\r\n-    CENVER           : 6, // version needed to extract\r\n-    CENFLG           : 8, // encrypt, decrypt flags\r\n-    CENHOW           : 10, // compression method\r\n-    CENTIM           : 12, // modification time (2 bytes time, 2 bytes date)\r\n-    CENCRC           : 16, // uncompressed file crc-32 value\r\n-    CENSIZ           : 20, // compressed size\r\n-    CENLEN           : 24, // uncompressed size\r\n-    CENNAM           : 28, // filename length\r\n-    CENEXT           : 30, // extra field length\r\n-    CENCOM           : 32, // file comment length\r\n-    CENDSK           : 34, // volume number start\r\n-    CENATT           : 36, // internal file attributes\r\n-    CENATX           : 38, // external file attributes (host system dependent)\r\n-    CENOFF           : 42, // LOC header offset\r\n-\r\n-    /* The entries in the end of central directory */\r\n-    ENDHDR           : 22, // END header size\r\n-    ENDSIG           : 0x06054b50, // \"PK\\005\\006\"\r\n-    ENDSUB           : 8, // number of entries on this disk\r\n-    ENDTOT           : 10, // total number of entries\r\n-    ENDSIZ           : 12, // central directory size in bytes\r\n-    ENDOFF           : 16, // offset of first CEN header\r\n-    ENDCOM           : 20, // zip file comment length\r\n-\r\n-    /* Compression methods */\r\n-    STORED           : 0, // no compression\r\n-    SHRUNK           : 1, // shrunk\r\n-    REDUCED1         : 2, // reduced with compression factor 1\r\n-    REDUCED2         : 3, // reduced with compression factor 2\r\n-    REDUCED3         : 4, // reduced with compression factor 3\r\n-    REDUCED4         : 5, // reduced with compression factor 4\r\n-    IMPLODED         : 6, // imploded\r\n-    // 7 reserved\r\n-    DEFLATED         : 8, // deflated\r\n-    ENHANCED_DEFLATED: 9, // enhanced deflated\r\n-    PKWARE           : 10,// PKWare DCL imploded\r\n-    // 11 reserved\r\n-    BZIP2            : 12, //  compressed using BZIP2\r\n-    // 13 reserved\r\n-    LZMA             : 14, // LZMA\r\n-    // 15-17 reserved\r\n-    IBM_TERSE        : 18, // compressed using IBM TERSE\r\n-    IBM_LZ77         : 19, //IBM LZ77 z\r\n-\r\n-    /* General purpose bit flag */\r\n-    FLG_ENC          : 0,  // encripted file\r\n-    FLG_COMP1        : 1,  // compression option\r\n-    FLG_COMP2        : 2,  // compression option\r\n-    FLG_DESC         : 4,  // data descriptor\r\n-    FLG_ENH          : 8,  // enhanced deflation\r\n-    FLG_STR          : 16, // strong encryption\r\n-    FLG_LNG          : 1024, // language encoding\r\n-    FLG_MSK          : 4096, // mask header values\r\n-\r\n-    /* Load type */\r\n-    FILE             : 0,\r\n-    BUFFER           : 1,\r\n-    NONE             : 2,\r\n-\r\n-    /* 4.5 Extensible data fields */\r\n-    EF_ID            : 0,\r\n-    EF_SIZE          : 2,\r\n-\r\n-    /* Header IDs */\r\n-    ID_ZIP64         : 0x0001,\r\n-    ID_AVINFO        : 0x0007,\r\n-    ID_PFS           : 0x0008,\r\n-    ID_OS2           : 0x0009,\r\n-    ID_NTFS          : 0x000a,\r\n-    ID_OPENVMS       : 0x000c,\r\n-    ID_UNIX          : 0x000d,\r\n-    ID_FORK          : 0x000e,\r\n",
					"match": false,
					"packageHash": "ce78798bffd06f405a96c04dbe994703c0b5c88dd70ded1608131520c5bde69a",
					"size": 4585,
					"sourceHash": "208e943a2e5faad056047f3c7991cce3cde637d8e272a564f2546210ebdf2069",
					"status": "content"
				},
				"util/errors.js": {
					"diff": "--- published/util/errors.js\n+++ rebuilt/util/errors.js\n@@ -1,35 +1,63 @@\n-module.exports = {\r\n-    /* Header error messages */\r\n-    \"INVALID_LOC\" : \"Invalid LOC header (bad signature)\",\r\n-    \"INVALID_CEN\" : \"Invalid CEN header (bad signature)\",\r\n-    \"INVALID_END\" : \"Invalid END header (bad signature)\",\r\n-\r\n-    /* ZipEntry error messages*/\r\n-    \"NO_DATA\" : \"Nothing to decompress\",\r\n-    \"BAD_CRC\" : \"CRC32 checksum failed\",\r\n-    \"FILE_IN_THE_WAY\" : \"There is a file in the way: %s\",\r\n-    \"UNKNOWN_METHOD\" : \"Invalid/unsupported compression method\",\r\n-\r\n-    /* Inflater error messages */\r\n-    \"AVAIL_DATA\" : \"inflate::Available inflate data did not terminate\",\r\n-    \"INVALID_DISTANCE\" : \"inflate::Invalid literal/length or distance code in fixed or dynamic block\",\r\n-    \"TO_MANY_CODES\" : \"inflate::Dynamic block code description: too many length or distance codes\",\r\n-    \"INVALID_REPEAT_LEN\" : \"inflate::Dynamic block code description: repeat more than specified lengths\",\r\n-    \"INVALID_REPEAT_FIRST\" : \"inflate::Dynamic block code description: repeat lengths with no first length\",\r\n-    \"INCOMPLETE_CODES\" : \"inflate::Dynamic block code description: code lengths codes incomplete\",\r\n-    \"INVALID_DYN_DISTANCE\": \"inflate::Dynamic block code description: invalid distance code lengths\",\r\n-    \"INVALID_CODES_LEN\": \"inflate::Dynamic block code description: invalid literal/length code lengths\",\r\n-    \"INVALID_STORE_BLOCK\" : \"inflate::Stored block length did not match one's complement\",\r\n-    \"INVALID_BLOCK_TYPE\" : \"inflate::Invalid block type (type == 3)\",\r\n-\r\n-    /* ADM-ZIP error messages */\r\n-    \"CANT_EXTRACT_FILE\" : \"Could not extract the file\",\r\n-    \"CANT_OVERRIDE\" : \"Target file already exists\",\r\n-    \"NO_ZIP\" : \"No zip file was loaded\",\r\n-    \"NO_ENTRY\" : \"Entry doesn't exist\",\r\n-    \"DIRECTORY_CONTENT_ERROR\" : \"A directory cannot have content\",\r\n-    \"FILE_NOT_FOUND\" : \"File not found: %s\",\r\n-    \"NOT_IMPLEMENTED\" : \"Not implemented\",\r\n-    \"INVALID_FILENAME\" : \"Invalid filename\",\r\n-    \"INVALID_FORMAT\" : \"Invalid or unsupported zip format. No END header found\"\r\n-};\n\\ No newline at end of file\n+const errors = {\n+    /* Header error messages */\n+    INVALID_LOC: \"Invalid LOC header (bad signature)\",\n+    INVALID_CEN: \"Invalid CEN header (bad signature)\",\n+    INVALID_END: \"Invalid END header (bad signature)\",\n+\n+    /* Descriptor */\n+    DESCRIPTOR_NOT_EXIST: \"No descriptor present\",\n+    DESCRIPTOR_UNKNOWN: \"Unknown descriptor format\",\n+    DESCRIPTOR_FAULTY: \"Descriptor data is malformed\",\n+\n+    /* ZipEntry error messages*/\n+    NO_DATA: \"Nothing to decompress\",\n+    BAD_CRC: \"CRC32 checksum failed {0}\",\n+    FILE_IN_THE_WAY: \"There is a file in the way: {0}\",\n+    UNKNOWN_METHOD: \"Invalid/unsupported compression method\",\n+\n+    /* Inflater error messages */\n+    AVAIL_DATA: \"inflate::Available inflate data did not terminate\",\n+    INVALID_DISTANCE: \"inflate::Invalid literal/length or distance code in fixed or dynamic block\",\n+    TO_MANY_CODES: \"inflate::Dynamic block code description: too many length or distance codes\",\n+    INVALID_REPEAT_LEN: \"inflate::Dynamic block code description: repeat more than specified lengths\",\n+    INVALID_REPEAT_FIRST: \"inflate::Dynamic block code description: repeat lengths with no first length\",\n+    INCOMPLETE_CODES: \"inflate::Dynamic block code description: code lengths codes incomplete\",\n+    INVALID_DYN_DISTANCE: \"inflate::Dynamic block code description: invalid distance code lengths\",\n+    INVALID_CODES_LEN: \"inflate::Dynamic block code description: invalid literal/length code lengths\",\n+    INVALID_STORE_BLOCK: \"inflate::Stored block length did not match one's complement\",\n+    INVALID_BLOCK_TYPE: \"inflate::Invalid block type (type == 3)\",\n+\n+    /* ADM-ZIP error messages */\n+    CANT_EXTRACT_FILE: \"Could not extract the file\",\n+    CANT_OVERRIDE: \"Target file already exists\",\n+    DISK_ENTRY_TOO_LARGE: \"Number of disk entries is too large\",\n+    NO_ZIP: \"No zip file was loaded\",\n+    NO_ENTRY: \"Entry doesn't exist\",\n+    DIRECTORY_CONTENT_ERROR: \"A directory cannot have content\",\n+    FILE_NOT_FOUND: 'File not found: \"{0}\"',\n+    NOT_IMPLEMENTED: \"Not implemented\",\n+    INVALID_FILENAME: \"Invalid filename\",\n+    INVALID_FORMAT: \"Invalid or unsupported zip format. No END header found\",\n+    INVALID_PASS_PARAM: \"Incompatible password parameter\",\n+    WRONG_PASSWORD: \"Wrong Password\",\n+\n+    /* ADM-ZIP */\n+    COMMENT_TOO_LONG: \"Comment is too long\", // Comment can be max 65535 bytes long (NOTE: some non-US characters may take more space)\n+    EXTRA_FIELD_PARSE_ERROR: \"Extra field parsing error\"\n+};\n+\n+// template\n+function E(message) {\n+    return function (...args) {\n+        if (args.length) { // Allow {0} .. {9} arguments in error message, based on argument number\n+            message = message.replace(/\\{(\\d)\\}/g, (_, n) => args[n] || '');\n+        }\n+\n+        return new Error('ADM-ZIP: ' + message);\n+    };\n+}\n+\n+// Init errors with template\n+for (const msg of Object.keys(errors)) {\n",
					"match": false,
					"packageHash": "91dcc9c0858ed467b7fb76be3e4e27f2bc10cc035c6e6daef852e9e55e16b1f9",
					"size": 1995,
					"sourceHash": "d2d243647737c795c2db8aeba2e1f3841d5f76370b521d436cf465322dd4aab7",
					"status": "content"
				},
				"util/fattr.js": {
					"diff": "--- published/util/fattr.js\n+++ rebuilt/util/fattr.js\n@@ -1,84 +1,76 @@\n-var fs = require(\"./fileSystem\").require(),\r\n-    pth = require(\"path\");\r\n-\t\r\n-fs.existsSync = fs.existsSync || pth.existsSync;\r\n-\r\n-module.exports = function(/*String*/path) {\r\n-\r\n-    var _path = path || \"\",\r\n-        _permissions = 0,\r\n-        _obj = newAttr(),\r\n-        _stat = null;\r\n-\r\n-    function newAttr() {\r\n-        return {\r\n-            directory : false,\r\n-            readonly : false,\r\n-            hidden : false,\r\n-            executable : false,\r\n-            mtime : 0,\r\n-            atime : 0\r\n-        }\r\n-    }\r\n-\r\n-    if (_path && fs.existsSync(_path)) {\r\n-        _stat = fs.statSync(_path);\r\n-        _obj.directory = _stat.isDirectory();\r\n-        _obj.mtime = _stat.mtime;\r\n-        _obj.atime = _stat.atime;\r\n-        _obj.executable = !!(1 & parseInt ((_stat.mode & parseInt (\"777\", 8)).toString (8)[0]));\r\n-        _obj.readonly = !!(2 & parseInt ((_stat.mode & parseInt (\"777\", 8)).toString (8)[0]));\r\n-        _obj.hidden = pth.basename(_path)[0] === \".\";\r\n-    } else {\r\n-        console.warn(\"Invalid path: \" + _path)\r\n-    }\r\n-\r\n-    return {\r\n-\r\n-        get directory () {\r\n-            return _obj.directory;\r\n-        },\r\n-\r\n-        get readOnly () {\r\n-            return _obj.readonly;\r\n-        },\r\n-\r\n-        get hidden () {\r\n-            return _obj.hidden;\r\n-        },\r\n-\r\n-        get mtime () {\r\n-            return _obj.mtime;\r\n-        },\r\n-\r\n-        get atime () {\r\n-           return _obj.atime;\r\n-        },\r\n-\r\n-\r\n-        get executable () {\r\n-            return _obj.executable;\r\n-        },\r\n-\r\n-        decodeAttributes : function(val) {\r\n-\r\n-        },\r\n-\r\n-        encodeAttributes : function (val) {\r\n-\r\n-        },\r\n-\r\n-        toString : function() {\r\n-           return '{\\n' +\r\n-               '\\t\"path\" : \"' + _path + \",\\n\" +\r\n-               '\\t\"isDirectory\" : ' + _obj.directory + \",\\n\" +\r\n-               '\\t\"isReadOnly\" : ' + _obj.readonly + \",\\n\" +\r\n-               '\\t\"isHidden\" : ' + _obj.hidden + \",\\n\" +\r\n-               '\\t\"isExecutable\" : ' + _obj.executable + \",\\n\" +\r\n-               '\\t\"mTime\" : ' + _obj.mtime + \"\\n\" +\r\n-               '\\t\"aTime\" : ' + _obj.atime + \"\\n\" +\r\n-           '}';\r\n-        }\r\n-    }\r\n-\r\n-};\r\n+const pth = require(\"path\");\n+\n+module.exports = function (/*String*/ path, /*Utils object*/ { fs }) {\n+    var _path = path || \"\",\n+        _obj = newAttr(),\n+        _stat = null;\n+\n+    function newAttr() {\n+        return {\n+            directory: false,\n+            readonly: false,\n+            hidden: false,\n+            executable: false,\n",
					"match": false,
					"packageHash": "1d44d31f7170283102a21eb9dd4fbcf7be1ec1d94a349a3ff7e702f4dbb505da",
					"size": 2125,
					"sourceHash": "31c93eb386a2bfbf19ad92a6bf20d510a8f1e7e90cc71d33dd888f89da12362d",
					"status": "content"
				},
				"util/fileSystem.js": {
					"match": false,
					"packageHash": "24010d8cecf657991c8befa059092210d629585563e87aee318cbb3a6a7fe262",
					"size": 274,
					"status": "missing-in-source"
				},
				"util/index.js": {
					"diff": "--- published/util/index.js\n+++ rebuilt/util/index.js\n@@ -1,5 +1,5 @@\n-module.exports = require(\"./utils\");\r\n-module.exports.FileSystem = require(\"./fileSystem\");\r\n-module.exports.Constants = require(\"./constants\");\r\n-module.exports.Errors = require(\"./errors\");\r\n-module.exports.FileAttr = require(\"./fattr\");\n\\ No newline at end of file\n+module.exports = require(\"./utils\");\n+module.exports.Constants = require(\"./constants\");\n+module.exports.Errors = require(\"./errors\");\n+module.exports.FileAttr = require(\"./fattr\");\n+module.exports.decoder = require(\"./decoder\");\n",
					"match": false,
					"packageHash": "d7b5da85a812f206cf8f49296af2f076644135e5af02862be85af4621abb7624",
					"size": 235,
					"sourceHash": "dc5b230ed853947ea55c0bf69f0e525fbeffefff09aa3da296d541bb8898314e",
					"status": "content"
				},
				"util/utils.js": {
					"diff": "--- published/util/utils.js\n+++ rebuilt/util/utils.js\n@@ -1,209 +1,336 @@\n-var fs = require(\"./fileSystem\").require(),\r\n-    pth = require('path');\r\n-\r\n-fs.existsSync = fs.existsSync || pth.existsSync;\r\n-\r\n-module.exports = (function() {\r\n-\r\n-    var crcTable = [],\r\n-        Constants = require('./constants'),\r\n-        Errors = require('./errors'),\r\n-\r\n-        PATH_SEPARATOR = pth.sep;\r\n-\r\n-\r\n-    function mkdirSync(/*String*/path) {\r\n-        var resolvedPath = path.split(PATH_SEPARATOR)[0];\r\n-        path.split(PATH_SEPARATOR).forEach(function(name) {\r\n-            if (!name || name.substr(-1,1) === \":\") return;\r\n-            resolvedPath += PATH_SEPARATOR + name;\r\n-            var stat;\r\n-            try {\r\n-                stat = fs.statSync(resolvedPath);\r\n-            } catch (e) {\r\n-                fs.mkdirSync(resolvedPath);\r\n-            }\r\n-            if (stat && stat.isFile())\r\n-                throw Errors.FILE_IN_THE_WAY.replace(\"%s\", resolvedPath);\r\n-        });\r\n-    }\r\n-\r\n-    function findSync(/*String*/dir, /*RegExp*/pattern, /*Boolean*/recoursive) {\r\n-        if (typeof pattern === 'boolean') {\r\n-            recoursive = pattern;\r\n-            pattern = undefined;\r\n-        }\r\n-        var files = [];\r\n-        fs.readdirSync(dir).forEach(function(file) {\r\n-            var path = pth.join(dir, file);\r\n-\r\n-            if (fs.statSync(path).isDirectory() && recoursive)\r\n-                files = files.concat(findSync(path, pattern, recoursive));\r\n-\r\n-            if (!pattern || pattern.test(path)) {\r\n-                files.push(pth.normalize(path) + (fs.statSync(path).isDirectory() ? PATH_SEPARATOR : \"\"));\r\n-            }\r\n-\r\n-        });\r\n-        return files;\r\n-    }\r\n-\r\n-    return {\r\n-        makeDir : function(/*String*/path) {\r\n-            mkdirSync(path);\r\n-        },\r\n-\r\n-        crc32 : function(buf) {\r\n-            if (typeof buf === 'string') {\r\n-                buf = Buffer.alloc(buf.length, buf);\r\n-            }\r\n-            var b = Buffer.alloc(4);\r\n-            if (!crcTable.length) {\r\n-                for (var n = 0; n < 256; n++) {\r\n-                    var c = n;\r\n-                    for (var k = 8; --k >= 0;)  //\r\n-                        if ((c & 1) !== 0)  { c = 0xedb88320 ^ (c >>> 1); } else { c = c >>> 1; }\r\n-                    if (c < 0) {\r\n-                        b.writeInt32LE(c, 0);\r\n-                        c = b.readUInt32LE(0);\r\n-                    }\r\n-                    crcTable[n] = c;\r\n-                }\r\n-            }\r\n-            var crc = 0, off = 0, len = buf.length, c1 = ~crc;\r\n-            while(--len >= 0) c1 = crcTable[(c1 ^ buf[off++]) & 0xff] ^ (c1 >>> 8);\r\n-            crc = ~c1;\r\n-            b.writeInt32LE(crc & 0xffffffff, 0);\r\n-            return b.readUInt32LE(0);\r\n-        },\r\n-\r\n-        methodToString : function(/*Number*/method) {\r\n-            switch (method) {\r\n-                case Constants.STORED:\r\n-                    return 'STORED (' + method + ')';\r\n-                case Constants.DEFLATED:\r\n-                    return 'DEFLATED (' + method + ')';\r\n-                default:\r\n-                    return 'UNSUPPORTED (' + method + ')';\r\n-            }\r\n-\r\n-        },\r\n-\r\n-        writeFileTo : function(/*String*/path, /*Buffer*/content, /*Boolean*/overwrite, /*Number*/attr) {\r\n-            if (fs.existsSync(path)) {\r\n-                if (!overwrite)\r\n-                    return false; // cannot overwrite\r\n-\r\n-                var stat = fs.statSync(path);\r\n",
					"match": false,
					"packageHash": "4b357bac623797d8b37c9eb3442c0d56b8fb93c1acf33605204bdffc28371a94",
					"size": 7353,
					"sourceHash": "a8983582ad5dfa163303d22acd0b0ab3312059a121fb1b377ad41f4a58ed955b",
					"status": "content"
				},
				"zipEntry.js": {
					"diff": "--- published/zipEntry.js\n+++ rebuilt/zipEntry.js\n@@ -1,290 +1,405 @@\n-var Utils = require(\"./util\"),\r\n-    Headers = require(\"./headers\"),\r\n-    Constants = Utils.Constants,\r\n-    Methods = require(\"./methods\");\r\n-\r\n-module.exports = function (/*Buffer*/input) {\r\n-\r\n-    var _entryHeader = new Headers.EntryHeader(),\r\n-        _entryName = Buffer.alloc(0),\r\n-        _comment = Buffer.alloc(0),\r\n-        _isDirectory = false,\r\n-        uncompressedData = null,\r\n-        _extra = Buffer.alloc(0);\r\n-\r\n-    function getCompressedDataFromZip() {\r\n-        if (!input || !Buffer.isBuffer(input)) {\r\n-            return Buffer.alloc(0);\r\n-        }\r\n-        _entryHeader.loadDataHeaderFromBinary(input);\r\n-        return input.slice(_entryHeader.realDataOffset, _entryHeader.realDataOffset + _entryHeader.compressedSize)\r\n-    }\r\n-\r\n-    function crc32OK(data) {\r\n-        // if bit 3 (0x08) of the general-purpose flags field is set, then the CRC-32 and file sizes are not known when the header is written\r\n-        if ((_entryHeader.flags & 0x8) !== 0x8) {\r\n-           if (Utils.crc32(data) !== _entryHeader.dataHeader.crc) {\r\n-               return false;\r\n-           }\r\n-        } else {\r\n-            // @TODO: load and check data descriptor header\r\n-            // The fields in the local header are filled with zero, and the CRC-32 and size are appended in a 12-byte structure\r\n-            // (optionally preceded by a 4-byte signature) immediately after the compressed data:\r\n-        }\r\n-        return true;\r\n-    }\r\n-\r\n-    function decompress(/*Boolean*/async, /*Function*/callback, /*String*/pass) {\r\n-        if(typeof callback === 'undefined' && typeof async === 'string') {\r\n-            pass=async;\r\n-            async=void 0;\r\n-        }\r\n-        if (_isDirectory) {\r\n-            if (async && callback) {\r\n-                callback(Buffer.alloc(0), Utils.Errors.DIRECTORY_CONTENT_ERROR); //si added error.\r\n-            }\r\n-            return Buffer.alloc(0);\r\n-        }\r\n-\r\n-        var compressedData = getCompressedDataFromZip();\r\n-       \r\n-        if (compressedData.length === 0) {\r\n-            if (async && callback) callback(compressedData, Utils.Errors.NO_DATA);//si added error.\r\n-            return compressedData;\r\n-        }\r\n-\r\n-        var data = Buffer.alloc(_entryHeader.size);\r\n-\r\n-        switch (_entryHeader.method) {\r\n-            case Utils.Constants.STORED:\r\n-                compressedData.copy(data);\r\n-                if (!crc32OK(data)) {\r\n-                    if (async && callback) callback(data, Utils.Errors.BAD_CRC);//si added error\r\n-                    return Utils.Errors.BAD_CRC;\r\n-                } else {//si added otherwise did not seem to return data.\r\n-                    if (async && callback) callback(data);\r\n-                    return data;\r\n-                }\r\n-            case Utils.Constants.DEFLATED:\r\n-                var inflater = new Methods.Inflater(compressedData);\r\n-                if (!async) {\r\n-                    var result = inflater.inflate(data);\r\n-                    result.copy(data, 0);\r\n-                    if (!crc32OK(data)) {\r\n-                        console.warn(Utils.Errors.BAD_CRC + \" \" + _entryName.toString())\r\n-                    }\r\n-                    return data;\r\n-                } else {\r\n-                    inflater.inflateAsync(function(result) {\r\n-                        result.copy(data, 0);\r\n-                        if (!crc32OK(data)) {\r\n-                            if (callback) callback(data, Utils.Errors.BAD_CRC); //si added error\r\n-                        } else { //si added otherwise did not seem to return data.\r\n-                            if (callback) callback(data);\r\n-                        }\r\n-                    })\r\n-                }\r\n-                break;\r\n-            default:\r\n-                if (async && callback) callback(Buffer.alloc(0), Utils.Errors.UNKNOWN_METHOD);\r\n-                return Utils.Errors.UNKNOWN_METHOD;\r\n-        }\r\n-    }\r\n-\r\n-    function compress(/*Boolean*/async, /*Function*/callback) {\r\n-        if ((!uncompressedData || !uncompressedData.length) && Buffer.isBuffer(input)) {\r\n-            // no data set or the data wasn't changed to require recompression\r\n-            if (async && callback) callback(getCompressedDataFromZip());\r\n",
					"match": false,
					"packageHash": "6d2a516453ff3f034c27f3c6fc46ba7b49ba2c7baf3bd41850fc966b80a36f59",
					"size": 11549,
					"sourceHash": "c60fed834d9b4e392d7da6c7eac833eedce8de64986801031b12fe4c2a8b061c",
					"status": "content"
				},
				"zipFile.js": {
					"diff": "--- published/zipFile.js\n+++ rebuilt/zipFile.js\n@@ -1,329 +1,446 @@\n-var ZipEntry = require(\"./zipEntry\"),\r\n-\tHeaders = require(\"./headers\"),\r\n-\tUtils = require(\"./util\");\r\n-\r\n-module.exports = function (/*String|Buffer*/input, /*Number*/inputType) {\r\n-\tvar entryList = [],\r\n-\t\tentryTable = {},\r\n-\t\t_comment = Buffer.alloc(0),\r\n-\t\tfilename = \"\",\r\n-\t\tfs = Utils.FileSystem.require(),\r\n-\t\tinBuffer = null,\r\n-\t\tmainHeader = new Headers.MainHeader();\r\n-\r\n-\tif (inputType === Utils.Constants.FILE) {\r\n-\t\t// is a filename\r\n-\t\tfilename = input;\r\n-\t\tinBuffer = fs.readFileSync(filename);\r\n-\t\treadMainHeader();\r\n-\t} else if (inputType === Utils.Constants.BUFFER) {\r\n-\t\t// is a memory buffer\r\n-\t\tinBuffer = input;\r\n-\t\treadMainHeader();\r\n-\t} else {\r\n-\t\t// none. is a new file\r\n-\t}\r\n-\r\n-\tfunction readEntries() {\r\n-\t\tentryTable = {};\r\n-\t\tentryList = new Array(mainHeader.diskEntries);  // total number of entries\r\n-\t\tvar index = mainHeader.offset;  // offset of first CEN header\r\n-\t\tfor (var i = 0; i < entryList.length; i++) {\r\n-\r\n-\t\t\tvar tmp = index,\r\n-\t\t\t\tentry = new ZipEntry(inBuffer);\r\n-\t\t\tentry.header = inBuffer.slice(tmp, tmp += Utils.Constants.CENHDR);\r\n-\r\n-\t\t\tentry.entryName = inBuffer.slice(tmp, tmp += entry.header.fileNameLength);\r\n-\r\n-\t\t\tif (entry.header.extraLength) {\r\n-\t\t\t\tentry.extra = inBuffer.slice(tmp, tmp += entry.header.extraLength);\r\n-\t\t\t}\r\n-\r\n-\t\t\tif (entry.header.commentLength)\r\n-\t\t\t\tentry.comment = inBuffer.slice(tmp, tmp + entry.header.commentLength);\r\n-\r\n-\t\t\tindex += entry.header.entryHeaderSize;\r\n-\r\n-\t\t\tentryList[i] = entry;\r\n-\t\t\tentryTable[entry.entryName] = entry;\r\n-\t\t}\r\n-\t}\r\n-\r\n-\tfunction readMainHeader() {\r\n-\t\tvar i = inBuffer.length - Utils.Constants.ENDHDR, // END header size\r\n-\t\t\tn = Math.max(0, i - 0xFFFF), // 0xFFFF is the max zip file comment length\r\n-\t\t\tendOffset = -1; // Start offset of the END header\r\n-\r\n-\t\tfor (i; i >= n; i--) {\r\n-\t\t\tif (inBuffer[i] !== 0x50) continue; // quick check that the byte is 'P'\r\n-\t\t\tif (inBuffer.readUInt32LE(i) === Utils.Constants.ENDSIG) { // \"PK\\005\\006\"\r\n-\t\t\t\tendOffset = i;\r\n-\t\t\t\tbreak;\r\n-\t\t\t}\r\n-\t\t}\r\n-\t\tif (!~endOffset)\r\n-\t\t\tthrow Utils.Errors.INVALID_FORMAT;\r\n-\r\n-\t\tmainHeader.loadFromBinary(inBuffer.slice(endOffset, endOffset + Utils.Constants.ENDHDR));\r\n-\t\tif (mainHeader.commentLength) {\r\n-\t\t\t_comment = inBuffer.slice(endOffset + Utils.Constants.ENDHDR);\r\n-\t\t}\r\n-\t\treadEntries();\r\n-\t}\r\n-\r\n-\treturn {\r\n-\t\t/**\r\n-\t\t * Returns an array of ZipEntry objects existent in the current opened archive\r\n-\t\t * @return Array\r\n-\t\t */\r\n-\t\tget entries() {\r\n-\t\t\treturn entryList;\r\n-\t\t},\r\n-\r\n-\t\t/**\r\n-\t\t * Archive comment\r\n-\t\t * @return {String}\r\n-\t\t */\r\n-\t\tget comment() {\r\n-\t\t\treturn _comment.toString();\r\n-\t\t},\r\n-\t\tset comment(val) {\r\n-\t\t\tmainHeader.commentLength = val.length;\r\n-\t\t\t_comment = val;\r\n-\t\t},\r\n-\r\n-\t\t/**\r\n-\t\t * Returns a reference to the entry with the given name or null if entry is inexistent\r\n",
					"match": false,
					"packageHash": "070dc283f45a6ccd477e5c5b6242396c1c051fefb74eaa329fa901ec87557cb6",
					"size": 9214,
					"sourceHash": "f95d3d6687e5ed959559943380e3bcf61f3e8849286d740afa45dedb28ffa16d",
					"status": "content"
				},
				"LICENSE": {
					"match": false,
					"status": "missing-in-package"
				},
				"methods/zipcrypto.js": {
					"match": false,
					"status": "missing-in-package"
				},
				"util/decoder.js": {
					"match": false,
					"status": "missing-in-package"
				}
			},
			"summary": {
				"differentFiles": 15,
				"matchingFiles": 1,
				"missingInPackage": 3,
				"missingInSource": 2,
				"score": 0.047619047619047616,
				"totalFiles": 21
			}
		}
	}
]
